---
title: "Modelling narrative similarity in autism and typical developing"
author: "Sarah K. Crockford"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

## Project Introduction

<INSERT HERE>

```{css style settings, echo=FALSE}
.link-style1 a {
  color: blue;
  text-decoration: underline;
}

.link-style2 a {
 color: blue;
}

Current institutional: .link-style1[[sarah.crockford@iit.it](mailto:sarah.crockford@iit.it)]

Personal: 
.link-style1[[sarah.crockford@iit.it](mailto:sarah.crockford@iit.it)]

```

```{r setup, include=FALSE}
rm(list=ls())
```

## Set up functions 

```{r custom functions}

# load video by video files

load_video_data <- function(datapath, video){
  
  #videopath <- file.path(datapath, video)
  
  filenames <- list.files(datapath, pattern="+.*csv")
  names2use <- sub(".csv", "", filenames)

  for(i in names2use){
    
      datafilepath <- file.path(videopath, paste(i,".csv",sep=""))
    
      assign(i, read.csv(datafilepath, 
                    header = TRUE, 
                    na.strings = "NaN", 
                    sep = ","))
 }

  # List of data frames to merge
  data_frames <- list(layer_0_clean_narratives,
                      layer_1_clean_narratives,
                      layer_2_clean_narratives,
                      layer_3_clean_narratives,
                      layer_4_clean_narratives,
                      layer_5_clean_narratives,
                      layer_6_clean_narratives,
                      layer_7_clean_narratives,
                      layer_8_clean_narratives,
                      layer_9_clean_narratives,
                      layer_10_clean_narratives,
                      layer_11_clean_narratives,
                      layer_12_clean_narratives)
  
  # grab intersection of two random dataframes
  intersection <- intersect(names(layer_0_clean_narratives), names(layer_1_clean_narratives))

  # Merge all data frames by "subids"
  video_data <- Reduce(function(x, y) merge(x, y, by = intersection), data_frames)
  
  # rename column names
  
  original_colname_list <- c("predicate_ratio",
                             "function_uniqueness",
                             "content_uniqueness",
                             "predicate_uniqueness",
                             "content_entropy_gpt_layer_0",
                             "function_entropy_gpt_layer_0",
                             "predicate_entropy_gpt_layer_0",
                             "content_entropy_gpt_layer_1",
                             "function_entropy_gpt_layer_1",
                             "predicate_entropy_gpt_layer_1",
                             "content_entropy_gpt_layer_2",
                             "function_entropy_gpt_layer_2",
                             "predicate_entropy_gpt_layer_2",
                             "content_entropy_gpt_layer_3",
                             "function_entropy_gpt_layer_3",
                             "predicate_entropy_gpt_layer_3",
                             "content_entropy_gpt_layer_4",
                             "function_entropy_gpt_layer_4",
                             "predicate_entropy_gpt_layer_4",
                             "content_entropy_gpt_layer_5",
                             "function_entropy_gpt_layer_5",
                             "predicate_entropy_gpt_layer_5",
                             "content_entropy_gpt_layer_6",
                             "function_entropy_gpt_layer_6",
                             "predicate_entropy_gpt_layer_6",
                             "content_entropy_gpt_layer_7",
                             "function_entropy_gpt_layer_7",
                             "predicate_entropy_gpt_layer_7",
                             "content_entropy_gpt_layer_8",
                             "function_entropy_gpt_layer_8",
                             "predicate_entropy_gpt_layer_8",
                             "content_entropy_gpt_layer_9",
                             "function_entropy_gpt_layer_9",
                             "predicate_entropy_gpt_layer_9",
                             "content_entropy_gpt_layer_10",
                             "function_entropy_gpt_layer_10",
                             "predicate_entropy_gpt_layer_10",
                             "content_entropy_gpt_layer_11",
                             "function_entropy_gpt_layer_11",
                             "predicate_entropy_gpt_layer_11",
                             "content_entropy_gpt_layer_12",
                             "function_entropy_gpt_layer_12",
                             "predicate_entropy_gpt_layer_12",
                             "content_entropy_bert_layer_0",
                             "function_entropy_bert_layer_0",
                             "predicate_entropy_bert_layer_0",
                             "content_entropy_bert_layer_1",
                             "function_entropy_bert_layer_1",
                             "predicate_entropy_bert_layer_1",
                             "content_entropy_bert_layer_2",
                             "function_entropy_bert_layer_2",
                             "predicate_entropy_bert_layer_2",
                             "content_entropy_bert_layer_3",
                             "function_entropy_bert_layer_3",
                             "predicate_entropy_bert_layer_3",
                             "content_entropy_bert_layer_4",
                             "function_entropy_bert_layer_4",
                             "predicate_entropy_bert_layer_4",
                             "content_entropy_bert_layer_5",
                             "function_entropy_bert_layer_5",
                             "predicate_entropy_bert_layer_5",
                             "content_entropy_bert_layer_6",
                             "function_entropy_bert_layer_6",
                             "predicate_entropy_bert_layer_6",
                             "content_entropy_bert_layer_7",
                             "function_entropy_bert_layer_7",
                             "predicate_entropy_bert_layer_7",
                             "content_entropy_bert_layer_8",
                             "function_entropy_bert_layer_8",
                             "predicate_entropy_bert_layer_8",
                             "content_entropy_bert_layer_9",
                             "function_entropy_bert_layer_9",
                             "predicate_entropy_bert_layer_9",
                             "content_entropy_bert_layer_10",
                             "function_entropy_bert_layer_10",
                             "predicate_entropy_bert_layer_10",
                             "content_entropy_bert_layer_11",
                             "function_entropy_bert_layer_11",
                             "predicate_entropy_bert_layer_11",
                             "content_entropy_bert_layer_12",
                             "function_entropy_bert_layer_12",
                             "predicate_entropy_bert_layer_12")
  
  new_colname_list <- lapply(original_colname_list, function(x) paste0(video, "_", x))
  
  names(video_data)[match(original_colname_list, names(video_data))] <- new_colname_list
  
  #video_data$subids <- as.character(video_data$subids)
  
  intersection_updated <- intersection[intersection != "subids"]
  
  video_data <- video_data[, !(names(video_data) %in% intersection_updated)]
  
  return(video_data)
  
}

# rank similarity dataframes

arrange_similarity_matrices <- function(sim2loopthrough, 
                                        ordered_subids_list, 
                                        condition,
                                        plot){
  
  dfnames <- data.frame()

  for (df in 1:length(sim2loopthrough)){
    
    name2use <- names(sim2loopthrough[df])
    
    df2use <- data.frame(sim2loopthrough[[df]])
    df2use$subids <- as.character(rownames(df2use))
    
    rank_name2use <- paste0("rank_", name2use, "_", condition)
    dfnames <- rbind(dfnames, rank_name2use)
    
    saveoutfilename <- paste0(rank_name2use, ".csv")
    saveoutfilepath <- file.path(resultpath, 
                                 'final_similarity_matrices', 
                                 saveoutfilename)

    #rank df by ordered subid_list
    ranked_df <- rank_subxsub_mat(df2use, 
                                  ordered_subids_list,
                                  "subids", 
                                  TRUE)
    assign(rank_name2use, ranked_df)
    
    if (plot == TRUE){
      write.csv(ranked_df, saveoutfilepath, row.names=FALSE)}
  
  } # end for loop
    
  rankdf2loopthrough <- do.call("list", mget(dfnames[[1]]))

  return(rankdf2loopthrough)

} # end function arrange_similarity_matrices

# compute mantel results

mantel_results_models <- function(x, y, nperm, n_models){
  
  # function takes two separate lists of dataframes as arguments
  # where x = list of data frames that model behvaioral similarity (4 models)
  # and y = list of data frames that model dependent variable similarity
  # nperm is the n of permutations you want to run (i.e. 1000)
  # n_models is the number of behavioral models you are using FIX ME
  
  # using package vegan for the mantel() function, with spearman method*
  # *because distribution of similarity is not parametric 
  # cit. https://jkzorz.github.io/2019/07/08/mantel-test.html
  
  # NB: switched to the vegan package, because the metan one was defaulting into 
  # spearman and there was no way to edit that (we need a non-parametric test)
  
  n_comparisons = length(y)
  
  len_final_df = n_models*n_comparisons
  
  model_res_r <- data.frame()
  model_res_p <- data.frame()
  rownames_df <- data.frame()
  
  modelname = names(x)
  comparisonname = names(y)
  
  for (i in 1:length(x)){
    for (j in 1:length(y)){
        
        result_name <- paste0(modelname[i], comparisonname[j])
  
        model2use = x[[i]]
        data2use = y[[j]]
  
        model_out = mantel(model2use, 
                           data2use, 
                           permutations = nperm, 
                           na.rm = TRUE)
  
        model_res_r <- rbind(model_res_r, model_out$statistic) # r-value
        model_res_p <- rbind(model_res_p, model_out$signif) # p-value
        
        rownames_df <- rbind(rownames_df, result_name)
    }}
  
  colnames(model_res_r) <- "r"
  colnames(model_res_p) <- "p_value"
  
  model_res <- cbind(model_res_p, model_res_r)
  rownames(model_res) <- rownames_df[[1]]
  
  model_res$p_value_adjusted <- p.adjust(model_res$p_value, method = "fdr")
  
  return(model_res)
  
} # end function mantel_results_models

# function to clean up the mantel results dataframe

clean_mantel_results <- function(all_model_res){
  
  # organize data so it's a little bit nicer to use

  id_stuff <- rownames(all_model_res) 
  all_model_res$lm_model <- ifelse(grepl("USE", id_stuff), 
                                   "USE",
                                  ifelse(grepl("BERT", id_stuff), 
                                         "BERT", "SGPT"))
  all_model_res$behav_model <- ifelse(grepl("nn", id_stuff),
                                      "nearest_neighbour",
                                      ifelse(grepl("div", id_stuff),
                                             "divergence",
                                             ifelse(grepl("conv", id_stuff), 
                                                    "convergence", "bow_tie")))
  rownames(all_model_res) <- 1:nrow(all_model_res)
  
  return(all_model_res)
}


# compute video similarity matrices 

pca_hurst <- function(hurst_df2use, 
                      pca2use, 
                      nblock, 
                      subid_list, 
                      group, 
                      condition){
  
  for (i in 1:nblock){
  
  hurst_list <- list(get(dfname_block1), 
                      get(dfname_block2), 
                      get(dfname_block3), 
                      get(dfname_block4), 
                      get(dfname_block5))}
  
  hurst_df <- hurst_list %>% reduce(full_join, by = "subid")

  rownames(hurst_df) <- hurst_df$subid
  hurst_df <- hurst_df[,-1]
  
  r_pearson_df <- data.frame()
  
  for (i in 1:nrow(hurst_df)) {
    for (j in 1:nrow(hurst_df)){
      
      vec_i <- hurst_df[i,]
      vec_j <- hurst_df[j,]
      
      r_pearson <- cor(vec_i, vec_j, method = "pearson")
      
      r_pearson_df[i, j] <- r_pearson
      
    }
  }
  
  return(r_pearson_df)
}

# borrowed function to fix column names because I can't be ffed waiting for python to run again
# https://stackoverflow.com/questions/10441437/why-am-i-getting-x-in-my-column-names-when-reading-a-data-frame

destroyX = function(es) {
  f = es
  for (col in c(1:ncol(f))){ #for each column in dataframe
    if (startsWith(colnames(f)[col], "X") == TRUE)  { #if starts with 'X' ..
      colnames(f)[col] <- substr(colnames(f)[col], 2, 100) #get rid of it
    }
  }
  assign(deparse(substitute(es)), f, inherits = TRUE) #assign corrected data to original name
}

```

## Set up enviornment 

If you have any issues with setting up the correct python env for reticulate, the following example below will work (copying and paste the below commands in the terminal from your base/home directory)

**NB: REQUIRES PANDAS AND NUMPY VERSIONS < 2.0**

```{r reticulate instructions, echo=FALSE}
knitr::include_graphics("/Users/scrockford/Library/CloudStorage/OneDrive-FondazioneIstitutoItalianoTecnologia/convergence_similarity/plots/how_2_setup_reticulate.png")
```


```{r load libraries, message = FALSE, warning = FALSE}
library(easypackages)

#IF YOU HAVE ISSUES WITH RETICULATE:
#https://stackoverflow.com/questions/50145643/unable-to-change-python-path-in-reticulate

libraries("here",
          "ggplot2",
          "tidyverse", 
          "psych", 
          "reticulate",
          "graph4lg", 
          "ade4", 
          "vegan",
          "similaritymodels",
          "caret",
          "tidyverse",
          "robustbase",
          "egg",
          "reshape2")

codepath = here("code")
resultpath = here("results")
datapath = here("data")
plotpath = here("plots")

#https://stackoverflow.com/questions/6736378/how-do-i-change-the-background-color-of-a-plot-made-with-ggplot2
mytheme <- list(
  theme_classic()+
    theme(panel.background = element_blank(),strip.background = element_rect(colour=NA, fill=NA),panel.border = element_rect(fill = NA, color = "black"),
          legend.title = element_blank(),legend.position="bottom", strip.text = element_text(face="bold", size=9),
          axis.text=element_text(face="bold"),axis.title = element_text(face="bold"),plot.title = element_text(face = "bold", hjust = 0.5,size=13))
)
```

# Get raw data filenames to read in 

```{r load in files, message = FALSE, warning = FALSE}

filenames <- list.files(path=datapath, pattern="+.*csv")
names2use <- sub(".csv", "", filenames)

for(i in names2use){
    
    datafilepath <- file.path(datapath, paste(i,".csv",sep=""))
    
    assign(i, 
           read.csv(datafilepath, 
                    header = TRUE, 
                    na.strings = "NaN", 
                    sep = ","))
}

# read pheno data file
phenofilename <- file.path(datapath, 
                           "pheno", 
                           "AIMSNeuroPsychData.csv")
pheno_data <- read.csv(phenofilename, 
                       header = TRUE,                     
                       na.strings = "NaN", 
                       sep = ";")

# read similarity matrices 
filenames <- list.files(path=resultpath, pattern="+.*csv")

for(i in filenames){
  
    datafilepath <- file.path(resultpath, i)
    name2use <- sub(".csv", "", i)
    
    assign(name2use, 
           read.csv(datafilepath, 
                    header = TRUE, 
                    na.strings = "NaN", 
                    sep = ",",
                    row.names = 1))
}

name2use <- 0

for (i in 1:length(filenames)) {
  name = filenames[i]
  if (grepl("INTRA", name)){
  name2use[i] <- sub(".csv", "", filenames[i])
}}

name2use <- Filter(function(a) any(!is.na(a)), name2use)

# get list of similarity matrices to loop through

sim2loopthrough <- do.call("list", mget(name2use))

for (i in 1:length(sim2loopthrough)){
  colnames(sim2loopthrough[[i]]) <- rownames(sim2loopthrough[[i]])
  value <- isSymmetric(data.matrix(sim2loopthrough[[i]]))
  message <- "Is my matrix symmetric?"
  print(paste0(message, " ", value))
  }

raw_data_transcript <- merge(raw_data_transcript, 
                             all_layers_video6, 
                             by = intersect(names(raw_data_transcript),
                                            names(all_layers_video6)))

#set seed
set.seed(999)

#set permutation runs for mantel test
nperm = 10000
#nperm = 10 # for testing purposes

#n of AQ similarity models we will build
n_behave_models = 3
```

## Store column name information

```{r gpt column name information}

column_function <- c("function_entropy_gpt_layer_0",
                      "function_entropy_gpt_layer_1",
                      "function_entropy_gpt_layer_2",
                      "function_entropy_gpt_layer_3",
                      "function_entropy_gpt_layer_4",
                      "function_entropy_gpt_layer_5",
                      "function_entropy_gpt_layer_6",
                      "function_entropy_gpt_layer_7",
                      "function_entropy_gpt_layer_8",
                      "function_entropy_gpt_layer_9",
                      "function_entropy_gpt_layer_10",
                      "function_entropy_gpt_layer_11",
                      "function_entropy_gpt_layer_12")


column_content <- c("content_entropy_gpt_layer_0",
                      "content_entropy_gpt_layer_1",
                      "content_entropy_gpt_layer_2",
                      "content_entropy_gpt_layer_3",
                      "content_entropy_gpt_layer_4",
                      "content_entropy_gpt_layer_5",
                      "content_entropy_gpt_layer_6",
                      "content_entropy_gpt_layer_7",
                      "content_entropy_gpt_layer_8",
                      "content_entropy_gpt_layer_9",
                      "content_entropy_gpt_layer_10",
                      "content_entropy_gpt_layer_11",
                      "content_entropy_gpt_layer_12")

column_predicate <- c("predicate_entropy_gpt_layer_0",
                      "predicate_entropy_gpt_layer_1",
                      "predicate_entropy_gpt_layer_2",
                      "predicate_entropy_gpt_layer_3",
                      "predicate_entropy_gpt_layer_4",
                      "predicate_entropy_gpt_layer_5",
                      "predicate_entropy_gpt_layer_6",
                      "predicate_entropy_gpt_layer_7",
                      "predicate_entropy_gpt_layer_8",
                      "predicate_entropy_gpt_layer_9",
                      "predicate_entropy_gpt_layer_10",
                      "predicate_entropy_gpt_layer_11",
                      "predicate_entropy_gpt_layer_12")

```

```{r column name information}

bertcolumn_function <- c("function_entropy_bert_layer_0",
                      "function_entropy_bert_layer_1",
                      "function_entropy_bert_layer_2",
                      "function_entropy_bert_layer_3",
                      "function_entropy_bert_layer_4",
                      "function_entropy_bert_layer_5",
                      "function_entropy_bert_layer_6",
                      "function_entropy_bert_layer_7",
                      "function_entropy_bert_layer_8",
                      "function_entropy_bert_layer_9",
                      "function_entropy_bert_layer_10",
                      "function_entropy_bert_layer_11",
                      "function_entropy_bert_layer_12")


bertcolumn_content <- c("content_entropy_bert_layer_0",
                      "content_entropy_bert_layer_1",
                      "content_entropy_bert_layer_2",
                      "content_entropy_bert_layer_3",
                      "content_entropy_bert_layer_4",
                      "content_entropy_bert_layer_5",
                      "content_entropy_bert_layer_6",
                      "content_entropy_bert_layer_7",
                      "content_entropy_bert_layer_8",
                      "content_entropy_bert_layer_9",
                      "content_entropy_bert_layer_10",
                      "content_entropy_bert_layer_11",
                      "content_entropy_bert_layer_12")

bertcolumn_predicate <- c("predicate_entropy_bert_layer_0",
                      "predicate_entropy_bert_layer_1",
                      "predicate_entropy_bert_layer_2",
                      "predicate_entropy_bert_layer_3",
                      "predicate_entropy_bert_layer_4",
                      "predicate_entropy_bert_layer_5",
                      "predicate_entropy_bert_layer_6",
                      "predicate_entropy_bert_layer_7",
                      "predicate_entropy_bert_layer_8",
                      "predicate_entropy_bert_layer_9",
                      "predicate_entropy_bert_layer_10",
                      "predicate_entropy_bert_layer_11",
                      "predicate_entropy_bert_layer_12")

```

## Rank phenotypic files by increasing Aq

```{r clean age data, warning=FALSE}

# rank phenotypic data files by increasing AQ

main_df_rank_byAQ <- raw_data_transcript[order(raw_data_transcript$AQ),]

AQ_list <- main_df_rank_byAQ$AQ
AQ_subids_list <- as.character(main_df_rank_byAQ$subids)

print(paste0("Mean AQ of sample: ", round(mean(AQ_list), 2)))
print(paste0("Standard deviation of AQ in sample: ", round(sd(AQ_list), 2)))
print(paste0("Maxmimum AQ of sample: ", max(AQ_list)))
print(paste0("Minimum AQ of sample: ", min(AQ_list)))

# set the center value for AQ as the mean between the max for td and min for asc

max <- raw_data_transcript %>% group_by(group) %>% summarise(mval=max(AQ))
min <- raw_data_transcript %>% group_by(group) %>% summarise(mval=min(AQ))

max_td <- max[[2,2]]
min_asc <- min[[1,2]]

mid_point <- min_asc + ((abs(max_td-min_asc))/2)

```

## Check AQ distribution 

```{r plot AQ}

count_list <- c("countvideo1",
                "countvideo2",
                "countvideo3",
                "countvideo4",
                "countvideo5",
                "countvideo6")

for (count in count_list){

  plot_AQ <- ggplot(main_df_rank_byAQ, 
                   aes(x = AQ, y = main_df_rank_byAQ[,count])) + 
              geom_point() + 
              geom_smooth(method = "lm") +
              labs(y = "word count") +
              mytheme

  print(plot_AQ)
}

plotAQ_x_EQ <- ggplot(raw_data_transcript, 
                   aes(x = AQ, y = EQ)) + 
               geom_point() + 
                geom_smooth(method = "lm") +
                mytheme

print(plot_AQ)
print(plotAQ_x_EQ)

```

```{r}
r_aq_function <- NA
r_cor_aq_function <- NA

plots_aq <- c()

for (i in 1:length(column_function)){
  
  column = column_function[i]
  
  plots_aq[[i]] <- raw_data_transcript %>% ggplot(aes(x = .data[["AQ"]], 
                                            y = .data[[column]])) +
              geom_point() +
              geom_smooth(method = "lm") +
              labs(x = paste0("GPT Layer ", i-1),
               y = " ") + mytheme
  
  cor_r_aq <- cor(raw_data_transcript[,column],
                  raw_data_transcript[,"AQ"])
  r_cor_aq_function[i] <- cor_r_aq
  
  model_aq <- lm(raw_data_transcript[,column] ~
                   raw_data_transcript[,"AQ"])
  
  print(paste0("Layer", i-1, "model for aq against function"))
  print(summary(model_aq))#$coefficients
  r2 = summary(model_aq)$r.squared
  adj_r2 = summary(model_aq)$adj.r.squared

  r_aq_function[i] <- adj_r2 
  
}

do.call(grid.arrange, plots_aq)
```

```{r}
r_aq_content <- NA
r_cor_aq_content <- NA

plots_aq <- c()

for (i in 1:length(column_content)){
  
  column = column_content[i]
  
  plots_aq[[i]] <- raw_data_transcript %>% ggplot(aes(x = .data[["AQ"]], 
                                            y = .data[[column]])) +
              geom_point() +
              geom_smooth(method = "lm") +
              labs(x = paste0("GPT Layer ", i-1),
               y = " ") + mytheme
  
  cor_r_aq <- cor(raw_data_transcript[,column],
                  raw_data_transcript[,"AQ"])
  r_cor_aq_content[i] <- cor_r_aq
  
  model_aq <- lm(raw_data_transcript[,column] ~
                   raw_data_transcript[,"AQ"])
  
  print(paste0("Layer", i-1, "model for aq against content"))
  print(summary(model_aq))#$coefficients
  r2 = summary(model_aq)$r.squared
  adj_r2 = summary(model_aq)$adj.r.squared

  r_aq_content[i] <- adj_r2 
  
}

do.call(grid.arrange, plots_aq)
```

```{r}
r_aq_predicate <- NA
r_cor_aq_predicate <- NA

plots_aq <- c()

for (i in 1:length(column_predicate)){
  
  column = column_predicate[i]
  
  plots_aq[[i]] <- raw_data_transcript %>% ggplot(aes(x = .data[["AQ"]], 
                                            y = .data[[column]])) +
              geom_point() +
              geom_smooth(method = "lm") +
              labs(x = paste0("GPT Layer ", i-1),
               y = " ") + mytheme
  
  cor_r_aq <- cor(raw_data_transcript[,column],
                  raw_data_transcript[,"AQ"])
  r_cor_aq_predicate[i] <- cor_r_aq
  
  model_aq <- lm(raw_data_transcript[,column] ~
                   raw_data_transcript[,"AQ"])
  
  print(paste0("Layer", i-1, "model for aq against predicate"))
  print(summary(model_aq))#$coefficients
  r2 = summary(model_aq)$r.squared
  adj_r2 = summary(model_aq)$adj.r.squared

  r_aq_predicate[i] <- adj_r2 
  
}

do.call(grid.arrange, plots_aq)
```


```{r}
r_aq_function <- NA
r_cor_aq_function <- NA

plots_aq <- c()

for (i in 1:length(bertcolumn_function)){
  
  column = bertcolumn_function[i]
  
  plots_aq[[i]] <- raw_data_transcript %>% ggplot(aes(x = .data[["AQ"]], 
                                            y = .data[[column]])) +
              geom_point() +
              geom_smooth(method = "lm") +
              labs(x = paste0("bert Layer ", i-1),
               y = " ") + mytheme
  
  cor_r_aq <- cor(raw_data_transcript[,column],
                  raw_data_transcript[,"AQ"])
  r_cor_aq_function[i] <- cor_r_aq
  
  model_aq <- lm(raw_data_transcript[,column] ~
                   raw_data_transcript[,"AQ"])
  
  print(paste0("Layer", i-1, "model for aq against function"))
  print(summary(model_aq))#$coefficients
  r2 = summary(model_aq)$r.squared
  adj_r2 = summary(model_aq)$adj.r.squared

  r_aq_function[i] <- adj_r2 
  
}

do.call(grid.arrange, plots_aq)
```

```{r}
r_aq_content <- NA
r_cor_aq_content <- NA

plots_aq <- c()

for (i in 1:length(bertcolumn_content)){
  
  column = bertcolumn_content[i]
  
  plots_aq[[i]] <- raw_data_transcript %>% ggplot(aes(x = .data[["AQ"]], 
                                            y = .data[[column]])) +
              geom_point() +
              geom_smooth(method = "lm") +
              labs(x = paste0("bert Layer ", i-1),
               y = " ") + mytheme
  
  cor_r_aq <- cor(raw_data_transcript[,column],
                  raw_data_transcript[,"AQ"])
  r_cor_aq_content[i] <- cor_r_aq
  
  model_aq <- lm(raw_data_transcript[,column] ~
                   raw_data_transcript[,"AQ"])
  
  print(paste0("Layer", i-1, "model for aq against content"))
  print(summary(model_aq))#$coefficients
  r2 = summary(model_aq)$r.squared
  adj_r2 = summary(model_aq)$adj.r.squared

  r_aq_content[i] <- adj_r2 
  
}

do.call(grid.arrange, plots_aq)
```

```{r}
r_aq_predicate <- NA
r_cor_aq_predicate <- NA

plots_aq <- c()

for (i in 1:length(bertcolumn_predicate)){
  
  column = bertcolumn_predicate[i]
  
  plots_aq[[i]] <- raw_data_transcript %>% ggplot(aes(x = .data[["AQ"]], 
                                            y = .data[[column]])) +
              geom_point() +
              geom_smooth(method = "lm") +
              labs(x = paste0("bert Layer ", i-1),
               y = " ") + mytheme
  
  cor_r_aq <- cor(raw_data_transcript[,column],
                  raw_data_transcript[,"AQ"])
  r_cor_aq_predicate[i] <- cor_r_aq
  
  model_aq <- lm(raw_data_transcript[,column] ~
                   raw_data_transcript[,"AQ"])
  
  print(paste0("Layer", i-1, "model for aq against predicate"))
  print(summary(model_aq))#$coefficients
  r2 = summary(model_aq)$r.squared
  adj_r2 = summary(model_aq)$adj.r.squared

  r_aq_predicate[i] <- adj_r2 
  
}

do.call(grid.arrange, plots_aq)
```


# Plot function word diversity of usage

```{r, message=FALSE, warning=FALSE}

n_layer = 13

video_list <- c("video1",
                "video2",
                "video3",
                "video4",
                "video5",
                "video6")

r_AQ_function <- data.frame(matrix(NA, 
                                   nrow = length(video_list), 
                                   ncol = n_layer))
r_AQ_function$video <- video_list

plots_video <- c()

#for (i in 1:length(video_list)){
i = 6
  column_function <- c("function_entropy_gpt_layer_0",
                        "function_entropy_gpt_layer_1",
                        "function_entropy_gpt_layer_2",
                        "function_entropy_gpt_layer_3",
                        "function_entropy_gpt_layer_4",
                        "function_entropy_gpt_layer_5",
                        "function_entropy_gpt_layer_6",
                        "function_entropy_gpt_layer_7",
                        "function_entropy_gpt_layer_8",
                        "function_entropy_gpt_layer_9",
                        "function_entropy_gpt_layer_10",
                        "function_entropy_gpt_layer_11",
                        "function_entropy_gpt_layer_12")
  
  plots_aq <- c()
  
  for (j in 1:length(new_colname_list)){
    
    column = new_colname_list[[j]]
    
    plot_AQ_func <- ggplot(main_df_rank_byAQ, aes(x = .data[["AQ"]], 
                                              y = .data[[column]])) + geom_point() + geom_smooth(method = "lm") + xlab("AQ") + ylab(paste0("layer_", j-1)) + mytheme
    
    #plots_aq[[j]] <- plot_AQ_func
    
    model_AQ <- lm(main_df_rank_byAQ[,column] ~ main_df_rank_byAQ[,"AQ"])
  
    #print(paste0("Layer", i-1, "model for AQ against function"))
    #summary(model_AQ)$coefficients
    r2 = summary(model_AQ)$r.squared
    adj_r2 = summary(model_AQ)$adj.r.squared
    #print(paste0("R^2 for layer", i-1, ": ", r2))
    #print(paste0("Adj. R^2 for layer", i-1, ": ", adj_r2))
    
    r_AQ_function[i,j] <- adj_r2 
    
    # Save the plot to a file
    file_name <- paste0("function_", video_list[i], "_layer_", j, ".jpeg")
    filepath <- file.path(plotpath, file_name)
    ggsave(filepath, plot = plot_AQ_func)
    
  }
#}

do.call(grid.arrange, plots_aq)
```

```{r}
# Initialize the list to store file names
file_names <- list()

# Loop through each video
for (i in 1:length(video_list)) {
  # Initialize the list to store file names for the current video
  video_file_names <- list()
  
  # Loop through each layer
  for (j in 1:length(column_function)) {
    file_name <- paste0("function_", video_list[i], "_layer_", j, ".jpeg")
    filepath <- file.path(plotpath, file_name)
    video_file_names[[j]] <- filepath
  }
  
  # Store the file names for the current video
  file_names[[i]] <- video_file_names
}

# Loop through each set of file names and arrange them
for (i in 1:length(file_names)) {
  video_file_names <- file_names[[i]]
  
  # Load the plots from the files
  plots <- lapply(video_file_names, function(file) ggdraw() + draw_image(file))
  
  # Arrange the plots into a grid
  arranged_plot <- do.call(grid.arrange, plots) #ggarrange(plotlist = plots)
  
  # Add a title to the arranged plot
  #final_plot <- annotate_figure(arranged_plot, top = text_grob(video_list[i], size = 14, face = "bold"))
  
  # Print the final plot
  #print(final_plot)
  
  file_name <- paste0("function_all_video", i, ".jpeg")
  filepath <- file.path(plotpath, file_name)
  ggsave(filepath, plot = final_plot)
  
}

```


# Plot content word diversity of AQ

```{r, message=FALSE, warning=FALSE}

video_list <- c("video1",
                "video2",
                "video3",
                "video4",
                "video5",
                "video6")

r_AQ_content <- data.frame(matrix(NA, nrow = length(video_list), ncol = n_layer))
r_AQ_content$video <- video_list

for (i in 1:length(video_list)){

  column_content <- c("content_entropy_gpt_layer_0",
                        "content_entropy_gpt_layer_1",
                        "content_entropy_gpt_layer_2",
                        "content_entropy_gpt_layer_3",
                        "content_entropy_gpt_layer_4",
                        "content_entropy_gpt_layer_5",
                        "content_entropy_gpt_layer_6",
                        "content_entropy_gpt_layer_7",
                        "content_entropy_gpt_layer_8",
                        "content_entropy_gpt_layer_9",
                        "content_entropy_gpt_layer_10",
                        "content_entropy_gpt_layer_11",
                        "content_entropy_gpt_layer_12")
  
  new_colname_list <- lapply(column_content, function(x) paste0(video_list[i], "_", x))
  
  for (j in 1:length(new_colname_list)){
    
    column = new_colname_list[[j]]
    
    plot_AQ_cont <- ggplot(main_df_rank_byAQ, aes(x = main_df_rank_byAQ[,"AQ"], 
                                              y = main_df_rank_byAQ[,column])) + geom_point() + geom_smooth(method = "lm") + xlab("AQ") + ylab(paste0("layer_", j-1))
    
    model_AQ <- lm(main_df_rank_byAQ[,column] ~ main_df_rank_byAQ[,"AQ"])
  
    #print(paste0("Layer", i-1, "model for AQ against content"))
    #summary(model_AQ)$coefficients
    r2 = summary(model_AQ)$r.squared
    adj_r2 = summary(model_AQ)$adj.r.squared
    #print(paste0("R^2 for layer", i-1, ": ", r2))
    #print(paste0("Adj. R^2 for layer", i-1, ": ", adj_r2))
    
    r_AQ_content[i,j] <- adj_r2 
    
    # Save the plot to a file
    file_name <- paste0("content_", video_list[i], "_layer_", j, ".jpeg")
    filepath <- file.path(plotpath, file_name)
    ggsave(filepath, plot = plot_AQ_cont)
    
  }
}

```

```{r}
# Initialize the list to store file names
file_names <- list()

# Loop through each video
for (i in 1:length(video_list)) {
  # Initialize the list to store file names for the current video
  video_file_names <- list()
  
  # Loop through each layer
  for (j in 1:length(column_content)) {
    file_name <- paste0("content_", video_list[i], "_layer_", j, ".jpeg")
    filepath <- file.path(plotpath, file_name)
    video_file_names[[j]] <- filepath
  }
  
  # Store the file names for the current video
  file_names[[i]] <- video_file_names
}

# Loop through each set of file names and arrange them
for (i in 1:length(file_names)) {
  video_file_names <- file_names[[i]]
  
  # Load the plots from the files
  plots <- lapply(video_file_names, function(file) ggdraw() + draw_image(file))
  
  # Arrange the plots into a grid
  arranged_plot <- ggarrange(plotlist = plots)
  
  # Add a title to the arranged plot
  final_plot <- annotate_figure(arranged_plot, top = text_grob(video_list[i], size = 14, face = "bold"))
  
  # Print the final plot
  #print(final_plot)
  
  file_name <- paste0("content_all_video", i, ".jpeg")
  filepath <- file.path(plotpath, file_name)
  ggsave(filepath, plot = final_plot)
  
}

```


# Plot verb diversity across layers

```{r, message=FALSE, warning=FALSE}

video_list <- c("video1",
                "video2",
                "video3",
                "video4",
                "video5",
                "video6")

r_AQ_predicate <- data.frame(matrix(NA, nrow = length(video_list), ncol = n_layer))
r_AQ_predicate$video <- video_list

for (i in 1:length(video_list)){

  column_predicate <- c("predicate_entropy_gpt_layer_0",
                        "predicate_entropy_gpt_layer_1",
                        "predicate_entropy_gpt_layer_2",
                        "predicate_entropy_gpt_layer_3",
                        "predicate_entropy_gpt_layer_4",
                        "predicate_entropy_gpt_layer_5",
                        "predicate_entropy_gpt_layer_6",
                        "predicate_entropy_gpt_layer_7",
                        "predicate_entropy_gpt_layer_8",
                        "predicate_entropy_gpt_layer_9",
                        "predicate_entropy_gpt_layer_10",
                        "predicate_entropy_gpt_layer_11",
                        "predicate_entropy_gpt_layer_12")
  
  new_colname_list <- lapply(column_predicate, function(x) paste0(video_list[i], "_", x))
  
  for (j in 1:length(new_colname_list)){
    
    column = new_colname_list[[j]]
    
    plot_AQ_pred <- ggplot(main_df_rank_byAQ, aes(x = main_df_rank_byAQ[,"AQ"], 
                                              y = main_df_rank_byAQ[,column])) + geom_point() + geom_smooth(method = "lm") + xlab("AQ") + ylab(paste0("layer_", j-1))
    
    model_AQ <- lm(main_df_rank_byAQ[,column] ~ main_df_rank_byAQ[,"AQ"])
  
    #print(paste0("Layer", i-1, "model for AQ against predicate"))
    #summary(model_AQ)$coefficients
    r2 = summary(model_AQ)$r.squared
    adj_r2 = summary(model_AQ)$adj.r.squared
    #print(paste0("R^2 for layer", i-1, ": ", r2))
    #print(paste0("Adj. R^2 for layer", i-1, ": ", adj_r2))
    
    r_AQ_predicate[i,j] <- adj_r2 
    
    # Save the plot to a file
    file_name <- paste0("predicate_", video_list[i], "_layer_", j, ".jpeg")
    filepath <- file.path(plotpath, file_name)
    ggsave(filepath, plot = plot_AQ_pred)
    
  }
}

```

```{r}
# Initialize the list to store file names
file_names <- list()

# Loop through each video
for (i in 1:length(video_list)) {
  # Initialize the list to store file names for the current video
  video_file_names <- list()
  
  # Loop through each layer
  for (j in 1:length(column_predicate)) {
    file_name <- paste0("predicate_", video_list[i], "_layer_", j, ".jpeg")
    filepath <- file.path(plotpath, file_name)
    video_file_names[[j]] <- filepath
  }
  
  # Store the file names for the current video
  file_names[[i]] <- video_file_names
}

# Loop through each set of file names and arrange them
for (i in 1:length(file_names)) {
  video_file_names <- file_names[[i]]
  
  # Load the plots from the files
  plots <- lapply(video_file_names, function(file) ggdraw() + draw_image(file))
  
  # Arrange the plots into a grid
  arranged_plot <- ggarrange(plotlist = plots)
  
  # Add a title to the arranged plot
  final_plot <- annotate_figure(arranged_plot, top = text_grob(video_list[i], size = 14, face = "bold"))
  
  # Print the final plot
  #print(final_plot)
  
  file_name <- paste0("predicate_all_video", i, ".jpeg")
  filepath <- file.path(plotpath, file_name)
  ggsave(filepath, plot = final_plot)
  
}

```

There is a strong, significantly positive relationship between AQ and predicate diversity, suggesting that as children AQ they use more 'diverse' predicates. From the word embeddings, we can glean this is most likely a combination of increasing vocabulary and more complex inflectional morphology (different tense AQ). 

```{r}

colnames(r_AQ_function)[1:13] <- as.factor(0:12)
colnames(r_AQ_content)[1:13] <- as.factor(0:12)
colnames(r_AQ_predicate)[1:13] <- as.factor(0:12)

r_values_long_func <- melt(r_AQ_function, id.vars = "video")
r_values_long_cont <- melt(r_AQ_content, id.vars = "video")
r_values_long_pred <- melt(r_AQ_predicate, id.vars = "video")

# Plot the data
all_plt1 <- ggplot(r_values_long_func, aes(x = variable, y = value, color = video, group = video)) +
  geom_line() +
  labs(title = "Function words",
       x = "Model layer",
       y = "R result diversity ~ AQ")

all_plt2 <- ggplot(r_values_long_cont, aes(x = variable, y = value, color = video, group = video)) +
  geom_line() +
  labs(title = "Content words",
       x = "Model layer",
       y = "R result diversity ~ AQ")

all_plt3 <- ggplot(r_values_long_pred, aes(x = variable, y = value, color = video, group = video)) +
  geom_line() +
  labs(title = "Predicate words",
       x = "Model layer",
       y = "R result diversity ~ AQ")

ggarrange(all_plt1,
          all_plt2,
          all_plt3)

```

## Steps of analysis I plan to do:

1. Create similarity matrix ranked in order of AQ/EQ (from lowest to highest):
          a. NEAREST NEIGHBOURS
          b. CONVERGENCE (min(i,j))
          c. DIVERGENCE (max(sample) - mean(i,j)) 
          
  NB: fixed divergence computation from min to mean (like Camacho)
          
  NB: through ranking these two variables, the subject list between matrices is no longer comparable! (i.e., subject ordering is different for AQ and EQ conditions)

2. Vectorize and compare narrative data, resulting in a sub x sub matrix of cosine similarity values (see accompanying python script).

3. Compare the two similarity matrices: do we find that pair similairty, convergence in age (or divergence) is related to similarity in narratives?

## Create age ranked similarity matrices

We are going to set plot to TRUE so that we save out our similarity matrices to plot them later using python.

```{r, message = FALSE, warning = FALSE}

AQ_ranked_sim2loopthrough <- arrange_similarity_matrices(sim2loopthrough, 
                              AQ_subids_list, 
                              "AQ",
                              plot = TRUE)

# EQ_ranked_sim2loopthrough <- arrange_similarity_matrices(sim2loopthrough, 
#                               EQ_subids_list, 
#                               "EQ",
#                               plot = TRUE)

saveoutfilepath <- file.path(resultpath, 'final_similarity_matrices', 'AQ_mat')

AQ_dataframes2loopthrough <- make_similarity_matrices(AQ_list, 
                                                      AQ_subids_list,
                                                      mid_point,
                                                      saveoutfilepath,
                                                      save_out = TRUE)

# saveoutfilepath <- file.path(resultpath, 'final_similarity_matrices', 'EQ_mat')
# 
# EQ_dataframes2loopthrough <- make_similarity_matrices(EQ_list, 
#                                                       EQ_subids_list,
#                                                       EQ_mid_point,
#                                                       saveoutfilepath,
#                                                       save_out = TRUE)

```


## Check similarity matrices

The following code plots the similarity matrices using python's seaborn.

It's a bit of a hack as you have to save out your similarity matrices into a your local folder and then re-import them into the python code (when you swap into python in R markdown you cannot carry over whatever is stored in your global environment, but it will re-set to whatever it last was once you exit python/this chunk). 

PS: I'm doing this because I find the python plots a lot nicer to look at then the R ones.

```{python plot, message = FALSE, warning = FALSE}
import numpy as np
import pandas as pd
import seaborn as sns
import glob
import os

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

path = "/Users/scrockford/Library/CloudStorage/OneDrive-FondazioneIstitutoItalianoTecnologia/triangle_similarity_language/results/final_similarity_matrices/AQ_mat/*.csv"

cmap = 'viridis'

for fname in glob.glob(path):

  data2plot = pd.read_csv(fname)
  plotname = os.path.basename(fname)
  plotname = plotname.replace(".csv", "")
  
  plt.figure()
  plt.title(plotname, fontsize =20)
  sns.heatmap(data2plot, cmap = cmap, square=True, cbar=True, xticklabels=False, yticklabels=False)
  
  plt.show()
  
```


```{python plot, message = FALSE, warning = FALSE}
import numpy as np
import pandas as pd
import seaborn as sns
import glob
import os

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

path = "/Users/scrockford/Library/CloudStorage/OneDrive-FondazioneIstitutoItalianoTecnologia/triangle_similarity_language/results/final_similarity_matrices/EQ_mat/*.csv"

cmap = 'viridis'

for fname in glob.glob(path):

  data2plot = pd.read_csv(fname)
  plotname = os.path.basename(fname)
  plotname = plotname.replace(".csv", "")
  
  plt.figure()
  plt.title(plotname, fontsize =20)
  sns.heatmap(data2plot, cmap = cmap, square=True, cbar=True, xticklabels=False, yticklabels=False)
  
  plt.show()
  
```


```{python plot, message = FALSE, warning = FALSE}
import numpy as np
import pandas as pd
import seaborn as sns
import glob
import os

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

path = "/Users/scrockford/Library/CloudStorage/OneDrive-FondazioneIstitutoItalianoTecnologia/triangle_similarity_language/results/final_similarity_matrices/*.csv"

cmap = 'viridis'

for fname in glob.glob(path):

  data2plot = pd.read_csv(fname)
  plotname = os.path.basename(fname)
  plotname = plotname.replace(".csv", "")
  
  plt.figure()
  plt.title(plotname, fontsize =20)
  sns.heatmap(data2plot, cmap = cmap, square=True, cbar=True, xticklabels=False, yticklabels=False)
  
  plt.show()
  
```

## Compute similarity between age and language

Final code runs a mantel test to check if the lower triangle of the nn, convergence, divergence and bow-tie sub x sub age models correlate with the lower triangle of the cosine similarity for the sub x sub narrative production data. 

Before running the final analysis, we check the relationship between each of the language model matrices to see how similar they are to each other.

The results return a Spearman's rank r, a raw p-value based on 10000 permutations of the lower triangle comparison and an FDR corrected (p-adjusted) p-value, corrected for all of the comparisons (4 age models * 3 language models, 12 comparisons). 

NB: Choice of this statistic is for consistency with Finn et al., 2020 and Camacho et al., 2023 method of analysis.  

# Check relationship between language model similarity matrices

```{r,  message = FALSE, warning = FALSE}

lm_res <-  mantel_results_models(AQ_ranked_sim2loopthrough, 
                                 AQ_ranked_sim2loopthrough,
                                 nperm,
                                 3)

print(lm_res)

```

# Check relationship between age and language model similarity matrices

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

model_res <-  mantel_results_models(AQ_dataframes2loopthrough, 
                                    AQ_ranked_sim2loopthrough,
                                    nperm,
                                    n_behave_models)

# organize data so it's a little bit nicer to use
final_model_res <- clean_mantel_results(model_res)
print(final_model_res)
saveoutfilepath <- file.path(resultpath, "model_results_output.csv")
write.csv(final_model_res, saveoutfilepath, row.names=FALSE)
```

```{r, message = FALSE, warning = FALSE}

# run mantel tests on each comparison and store results 

model_res <-  mantel_results_models(EQ_dataframes2loopthrough, 
                                    EQ_ranked_sim2loopthrough,
                                    nperm,
                                    n_behave_models)

# organize data so it's a little bit nicer to use
final_model_res <- clean_mantel_results(model_res)
print(final_model_res)
saveoutfilepath <- file.path(resultpath, "EQ_model_results_output.csv")
write.csv(final_model_res, saveoutfilepath, row.names=FALSE)
```
