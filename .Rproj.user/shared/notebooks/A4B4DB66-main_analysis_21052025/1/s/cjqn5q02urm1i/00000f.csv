"0",""
"0","# load video by video files"
"0",""
"0","load_video_data <- function(datapath, video){"
"0","  "
"0","  #videopath <- file.path(datapath, video)"
"0","  "
"0","  filenames <- list.files(datapath, pattern=""+.*csv"")"
"0","  names2use <- sub("".csv"", """", filenames)"
"0",""
"0","  for(i in names2use){"
"0","    "
"0","      datafilepath <- file.path(videopath, paste(i,"".csv"",sep=""""))"
"0","    "
"0","      assign(i, read.csv(datafilepath, "
"0","                    header = TRUE, "
"0","                    na.strings = ""NaN"", "
"0","                    sep = "",""))"
"0"," }"
"0",""
"0","  # List of data frames to merge"
"0","  data_frames <- list(layer_0_clean_narratives,"
"0","                      layer_1_clean_narratives,"
"0","                      layer_2_clean_narratives,"
"0","                      layer_3_clean_narratives,"
"0","                      layer_4_clean_narratives,"
"0","                      layer_5_clean_narratives,"
"0","                      layer_6_clean_narratives,"
"0","                      layer_7_clean_narratives,"
"0","                      layer_8_clean_narratives,"
"0","                      layer_9_clean_narratives,"
"0","                      layer_10_clean_narratives,"
"0","                      layer_11_clean_narratives,"
"0","                      layer_12_clean_narratives)"
"0","  "
"0","  # grab intersection of two random dataframes"
"0","  intersection <- intersect(names(layer_0_clean_narratives), names(layer_1_clean_narratives))"
"0",""
"0","  # Merge all data frames by ""subids"""
"0","  video_data <- Reduce(function(x, y) merge(x, y, by = intersection), data_frames)"
"0","  "
"0","  # rename column names"
"0","  "
"0","  original_colname_list <- c(""predicate_ratio"","
"0","                             ""function_uniqueness"","
"0","                             ""content_uniqueness"","
"0","                             ""predicate_uniqueness"","
"0","                             ""content_entropy_gpt_layer_0"","
"0","                             ""function_entropy_gpt_layer_0"","
"0","                             ""predicate_entropy_gpt_layer_0"","
"0","                             ""content_entropy_gpt_layer_1"","
"0","                             ""function_entropy_gpt_layer_1"","
"0","                             ""predicate_entropy_gpt_layer_1"","
"0","                             ""content_entropy_gpt_layer_2"","
"0","                             ""function_entropy_gpt_layer_2"","
"0","                             ""predicate_entropy_gpt_layer_2"","
"0","                             ""content_entropy_gpt_layer_3"","
"0","                             ""function_entropy_gpt_layer_3"","
"0","                             ""predicate_entropy_gpt_layer_3"","
"0","                             ""content_entropy_gpt_layer_4"","
"0","                             ""function_entropy_gpt_layer_4"","
"0","                             ""predicate_entropy_gpt_layer_4"","
"0","                             ""content_entropy_gpt_layer_5"","
"0","                             ""function_entropy_gpt_layer_5"","
"0","                             ""predicate_entropy_gpt_layer_5"","
"0","                             ""content_entropy_gpt_layer_6"","
"0","                             ""function_entropy_gpt_layer_6"","
"0","                             ""predicate_entropy_gpt_layer_6"","
"0","                             ""content_entropy_gpt_layer_7"","
"0","                             ""function_entropy_gpt_layer_7"","
"0","                             ""predicate_entropy_gpt_layer_7"","
"0","                             ""content_entropy_gpt_layer_8"","
"0","                             ""function_entropy_gpt_layer_8"","
"0","                             ""predicate_entropy_gpt_layer_8"","
"0","                             ""content_entropy_gpt_layer_9"","
"0","                             ""function_entropy_gpt_layer_9"","
"0","                             ""predicate_entropy_gpt_layer_9"","
"0","                             ""content_entropy_gpt_layer_10"","
"0","                             ""function_entropy_gpt_layer_10"","
"0","                             ""predicate_entropy_gpt_layer_10"","
"0","                             ""content_entropy_gpt_layer_11"","
"0","                             ""function_entropy_gpt_layer_11"","
"0","                             ""predicate_entropy_gpt_layer_11"","
"0","                             ""content_entropy_gpt_layer_12"","
"0","                             ""function_entropy_gpt_layer_12"","
"0","                             ""predicate_entropy_gpt_layer_12"","
"0","                             ""content_entropy_bert_layer_0"","
"0","                             ""function_entropy_bert_layer_0"","
"0","                             ""predicate_entropy_bert_layer_0"","
"0","                             ""content_entropy_bert_layer_1"","
"0","                             ""function_entropy_bert_layer_1"","
"0","                             ""predicate_entropy_bert_layer_1"","
"0","                             ""content_entropy_bert_layer_2"","
"0","                             ""function_entropy_bert_layer_2"","
"0","                             ""predicate_entropy_bert_layer_2"","
"0","                             ""content_entropy_bert_layer_3"","
"0","                             ""function_entropy_bert_layer_3"","
"0","                             ""predicate_entropy_bert_layer_3"","
"0","                             ""content_entropy_bert_layer_4"","
"0","                             ""function_entropy_bert_layer_4"","
"0","                             ""predicate_entropy_bert_layer_4"","
"0","                             ""content_entropy_bert_layer_5"","
"0","                             ""function_entropy_bert_layer_5"","
"0","                             ""predicate_entropy_bert_layer_5"","
"0","                             ""content_entropy_bert_layer_6"","
"0","                             ""function_entropy_bert_layer_6"","
"0","                             ""predicate_entropy_bert_layer_6"","
"0","                             ""content_entropy_bert_layer_7"","
"0","                             ""function_entropy_bert_layer_7"","
"0","                             ""predicate_entropy_bert_layer_7"","
"0","                             ""content_entropy_bert_layer_8"","
"0","                             ""function_entropy_bert_layer_8"","
"0","                             ""predicate_entropy_bert_layer_8"","
"0","                             ""content_entropy_bert_layer_9"","
"0","                             ""function_entropy_bert_layer_9"","
"0","                             ""predicate_entropy_bert_layer_9"","
"0","                             ""content_entropy_bert_layer_10"","
"0","                             ""function_entropy_bert_layer_10"","
"0","                             ""predicate_entropy_bert_layer_10"","
"0","                             ""content_entropy_bert_layer_11"","
"0","                             ""function_entropy_bert_layer_11"","
"0","                             ""predicate_entropy_bert_layer_11"","
"0","                             ""content_entropy_bert_layer_12"","
"0","                             ""function_entropy_bert_layer_12"","
"0","                             ""predicate_entropy_bert_layer_12"")"
"0","  "
"0","  new_colname_list <- lapply(original_colname_list, function(x) paste0(video, ""_"", x))"
"0","  "
"0","  names(video_data)[match(original_colname_list, names(video_data))] <- new_colname_list"
"0","  "
"0","  #video_data$subids <- as.character(video_data$subids)"
"0","  "
"0","  intersection_updated <- intersection[intersection != ""subids""]"
"0","  "
"0","  video_data <- video_data[, !(names(video_data) %in% intersection_updated)]"
"0","  "
"0","  return(video_data)"
"0","  "
"0","}"
"0",""
"0","# rank similarity dataframes"
"0",""
"0","arrange_similarity_matrices <- function(sim2loopthrough, "
"0","                                        ordered_subids_list, "
"0","                                        condition,"
"0","                                        plot){"
"0","  "
"0","  dfnames <- data.frame()"
"0",""
"0","  for (df in 1:length(sim2loopthrough)){"
"0","    "
"0","    name2use <- names(sim2loopthrough[df])"
"0","    "
"0","    df2use <- data.frame(sim2loopthrough[[df]])"
"0","    df2use$subids <- as.character(rownames(df2use))"
"0","    "
"0","    rank_name2use <- paste0(""rank_"", name2use, ""_"", condition)"
"0","    dfnames <- rbind(dfnames, rank_name2use)"
"0","    "
"0","    saveoutfilename <- paste0(rank_name2use, "".csv"")"
"0","    saveoutfilepath <- file.path(resultpath, "
"0","                                 'final_similarity_matrices', "
"0","                                 saveoutfilename)"
"0",""
"0","    #rank df by ordered subid_list"
"0","    ranked_df <- rank_subxsub_mat(df2use, "
"0","                                  ordered_subids_list,"
"0","                                  ""subids"", "
"0","                                  TRUE)"
"0","    assign(rank_name2use, ranked_df)"
"0","    "
"0","    if (plot == TRUE){"
"0","      write.csv(ranked_df, saveoutfilepath, row.names=FALSE)}"
"0","  "
"0","  } # end for loop"
"0","    "
"0","  rankdf2loopthrough <- do.call(""list"", mget(dfnames[[1]]))"
"0",""
"0","  return(rankdf2loopthrough)"
"0",""
"0","} # end function arrange_similarity_matrices"
"0",""
"0","# compute mantel results"
"0",""
"0","mantel_results_models <- function(x, y, nperm, n_models){"
"0","  "
"0","  # function takes two separate lists of dataframes as arguments"
"0","  # where x = list of data frames that model behvaioral similarity (4 models)"
"0","  # and y = list of data frames that model dependent variable similarity"
"0","  # nperm is the n of permutations you want to run (i.e. 1000)"
"0","  # n_models is the number of behavioral models you are using FIX ME"
"0","  "
"0","  # using package vegan for the mantel() function, with spearman method*"
"0","  # *because distribution of similarity is not parametric "
"0","  # cit. https://jkzorz.github.io/2019/07/08/mantel-test.html"
"0","  "
"0","  # NB: switched to the vegan package, because the metan one was defaulting into "
"0","  # spearman and there was no way to edit that (we need a non-parametric test)"
"0","  "
"0","  n_comparisons = length(y)"
"0","  "
"0","  len_final_df = n_models*n_comparisons"
"0","  "
"0","  model_res_r <- data.frame()"
"0","  model_res_p <- data.frame()"
"0","  rownames_df <- data.frame()"
"0","  "
"0","  modelname = names(x)"
"0","  comparisonname = names(y)"
"0","  "
"0","  for (i in 1:length(x)){"
"0","    for (j in 1:length(y)){"
"0","        "
"0","        result_name <- paste0(modelname[i], comparisonname[j])"
"0","  "
"0","        model2use = x[[i]]"
"0","        data2use = y[[j]]"
"0","  "
"0","        model_out = mantel(model2use, "
"0","                           data2use, "
"0","                           permutations = nperm, "
"0","                           na.rm = TRUE)"
"0","  "
"0","        model_res_r <- rbind(model_res_r, model_out$statistic) # r-value"
"0","        model_res_p <- rbind(model_res_p, model_out$signif) # p-value"
"0","        "
"0","        rownames_df <- rbind(rownames_df, result_name)"
"0","    }}"
"0","  "
"0","  colnames(model_res_r) <- ""r"""
"0","  colnames(model_res_p) <- ""p_value"""
"0","  "
"0","  model_res <- cbind(model_res_p, model_res_r)"
"0","  rownames(model_res) <- rownames_df[[1]]"
"0","  "
"0","  model_res$p_value_adjusted <- p.adjust(model_res$p_value, method = ""fdr"")"
"0","  "
"0","  return(model_res)"
"0","  "
"0","} # end function mantel_results_models"
"0",""
"0","# function to clean up the mantel results dataframe"
"0",""
"0","clean_mantel_results <- function(all_model_res){"
"0","  "
"0","  # organize data so it's a little bit nicer to use"
"0",""
"0","  id_stuff <- rownames(all_model_res) "
"0","  all_model_res$lm_model <- ifelse(grepl(""USE"", id_stuff), "
"0","                                   ""USE"","
"0","                                  ifelse(grepl(""BERT"", id_stuff), "
"0","                                         ""BERT"", ""SGPT""))"
"0","  all_model_res$behav_model <- ifelse(grepl(""nn"", id_stuff),"
"0","                                      ""nearest_neighbour"","
"0","                                      ifelse(grepl(""div"", id_stuff),"
"0","                                             ""divergence"","
"0","                                             ifelse(grepl(""conv"", id_stuff), "
"0","                                                    ""convergence"", ""bow_tie"")))"
"0","  rownames(all_model_res) <- 1:nrow(all_model_res)"
"0","  "
"0","  return(all_model_res)"
"0","}"
"0",""
"0",""
"0","# compute video similarity matrices "
"0",""
"0","pca_hurst <- function(hurst_df2use, "
"0","                      pca2use, "
"0","                      nblock, "
"0","                      subid_list, "
"0","                      group, "
"0","                      condition){"
"0","  "
"0","  for (i in 1:nblock){"
"0","  "
"0","  hurst_list <- list(get(dfname_block1), "
"0","                      get(dfname_block2), "
"0","                      get(dfname_block3), "
"0","                      get(dfname_block4), "
"0","                      get(dfname_block5))}"
"0","  "
"0","  hurst_df <- hurst_list %>% reduce(full_join, by = ""subid"")"
"0",""
"0","  rownames(hurst_df) <- hurst_df$subid"
"0","  hurst_df <- hurst_df[,-1]"
"0","  "
"0","  r_pearson_df <- data.frame()"
"0","  "
"0","  for (i in 1:nrow(hurst_df)) {"
"0","    for (j in 1:nrow(hurst_df)){"
"0","      "
"0","      vec_i <- hurst_df[i,]"
"0","      vec_j <- hurst_df[j,]"
"0","      "
"0","      r_pearson <- cor(vec_i, vec_j, method = ""pearson"")"
"0","      "
"0","      r_pearson_df[i, j] <- r_pearson"
"0","      "
"0","    }"
"0","  }"
"0","  "
"0","  return(r_pearson_df)"
"0","}"
"0",""
"0","# borrowed function to fix column names because I can't be ffed waiting for python to run again"
"0","# https://stackoverflow.com/questions/10441437/why-am-i-getting-x-in-my-column-names-when-reading-a-data-frame"
"0",""
"0","destroyX = function(es) {"
"0","  f = es"
"0","  for (col in c(1:ncol(f))){ #for each column in dataframe"
"0","    if (startsWith(colnames(f)[col], ""X"") == TRUE)  { #if starts with 'X' .."
"0","      colnames(f)[col] <- substr(colnames(f)[col], 2, 100) #get rid of it"
"0","    }"
"0","  }"
"0","  assign(deparse(substitute(es)), f, inherits = TRUE) #assign corrected data to original name"
"0","}"
"0",""
